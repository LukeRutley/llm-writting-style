{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663eaf63",
   "metadata": {},
   "source": [
    "# Fine-Tuning Dataset for Writing Style Creation\n",
    "\n",
    "This notebook demonstrates a scalable, automated approach for creating a high-quality fine-tuning dataset for writing style, following the methodology described in `README.md`. The process extracts human-written paragraphs, generates LLM-rewritten versions, and formats the data for OpenAI fine-tuning. Crucially, this approach does not require any human work to create a training dataset and means that any idivdual or organsiation posessing a corpus of human written documents can quickly obtain a high quality dataset for fine-tuning in their own style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fde3cc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6ee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "import openai\n",
    "import csv\n",
    "import docx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac89aed",
   "metadata": {},
   "source": [
    "## 1. PDF and DOCX to Text Conversion\n",
    "\n",
    "The first step in the pipeline is to convert all PDF and DOCX documents in the `Corpus/` directory to plain text files in `Corpus-txt/`. This ensures that the text is accessible for further processing.\n",
    "\n",
    "The following code uses PyPDF2 to extract text from each page of every PDF, and python-docx to extract text from DOCX files, saving the result as a `.txt` file.\n",
    "\n",
    ">**Note: You must have the folder `Corpus/` in the same path as this notebook. The folder should contain PDF and/or DOCX files containing your human writing for training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = ''\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + '\\n'\n",
    "    return text\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    text = '\\n'.join([para.text for para in doc.paragraphs if para.text.strip()])\n",
    "    return text\n",
    "\n",
    "corpus_dir = 'Corpus'\n",
    "corpus_txt_dir = 'Corpus-txt'\n",
    "os.makedirs(corpus_txt_dir, exist_ok=True)\n",
    "for filename in os.listdir(corpus_dir):\n",
    "    file_path = os.path.join(corpus_dir, filename)\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "        txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "    elif filename.lower().endswith('.docx'):\n",
    "        text = extract_text_from_docx(file_path)\n",
    "        txt_filename = os.path.splitext(filename)[0] + '.txt'\n",
    "    else:\n",
    "        continue\n",
    "    txt_path = os.path.join(corpus_txt_dir, txt_filename)\n",
    "    with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b26773",
   "metadata": {},
   "source": [
    "## 2. Extracting High-Quality Paragraphs with LLM\n",
    "\n",
    "After converting documents to text, the next step is to extract only the high-quality, full paragraphs from the text files. This judgement call is done using an LLM with a prompt that instructs the model to return only meaningful, well-formed paragraphs.\n",
    "\n",
    "GPT-4.1-mini is used becuase the high default rate limits allow quick processing of large input documents vs GPT-4.1 full, and mini appears to perform sufficiently for this task.\n",
    "\n",
    "The following code reads each `.txt` file from the `Corpus-txt/` directory, sends its content to the LLM, and writes the deliminated, full paragraphs to the `Corpus-Processed/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d51a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "client = openai.OpenAI()\n",
    "\n",
    "EXTRACTION_SYSTEM_PROMPT = (\n",
    "    'Your task is to extract all full paragraphs from the input you are provided. ' \n",
    "    'You should return each full paragraph delimitated by NEWPARAGRAPH. ' \n",
    "    'If text is not a full paragraph, do not include it in the output. ' \n",
    "    'You should only output meaningful paragraphs that are good examples of writing in full prose.'\n",
    ")\n",
    "\n",
    "def find_paragraphs(text):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': EXTRACTION_SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': text}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "    )\n",
    "    output = response.choices[0].message.content\n",
    "    return output\n",
    "\n",
    "processed_dir = 'Corpus-Processed'\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "for filename in os.listdir(corpus_txt_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(corpus_txt_dir, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        paragraphs = find_paragraphs(text)\n",
    "        processed_path = os.path.join(processed_dir, filename)\n",
    "        with open(processed_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79fbf4",
   "metadata": {},
   "source": [
    "## 3. Save Extracted Paragraphs to CSV\n",
    "\n",
    "The extracted paragraphs are split using the `NEWPARAGRAPH` delimiter and saved to a CSV file. This file will be used as input for the next step in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ad0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_csv = 'extracted_paragraphs.csv'\n",
    "all_paragraphs = []\n",
    "\n",
    "for filename in os.listdir(processed_dir):\n",
    "    if filename.endswith('.txt'):\n",
    "        processed_path = os.path.join(processed_dir, filename)\n",
    "        with open(processed_path, 'r', encoding='utf-8') as infile:\n",
    "            content = infile.read()\n",
    "        paragraphs = [p.strip() for p in content.split('NEWPARAGRAPH') if p.strip()]\n",
    "        all_paragraphs.extend(paragraphs)\n",
    "\n",
    "with open(extracted_csv, 'w', encoding='utf-8', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['human_version'])\n",
    "    for para in all_paragraphs:\n",
    "        writer.writerow([para])\n",
    "\n",
    "print(f'Extracted {len(all_paragraphs)} paragraphs from all files to {extracted_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e3d72",
   "metadata": {},
   "source": [
    "## 4. Rewrite Paragraphs with LLM\n",
    "\n",
    "After extracting high-quality paragraphs, each paragraph is rewritten using GPT-4.1 to create the 'LLM version'.\n",
    "\n",
    "The rewritten versions will serve as the 'input' for fine-tuning, with the human version human-written paragraphs as the 'target' output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f53f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewritten_csv = 'rewritten_paragraphs.csv'\n",
    "\n",
    "REWRITE_SYSTEM_PROMPT = 'You are a report writing editor. Respond with the re-written text only, without any additional commentary or explanation.'\n",
    "REWRITE_USER_TEMPLATE = (\n",
    "    'Re-write the following text to make it as good as possible. You should maintain all the meaning, '\n",
    "    'however you should change order, structure, word choice etc. to improve it. Input text: {}'\n",
    ")\n",
    "\n",
    "def rewrite_paragraph(paragraph):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4.1',\n",
    "        messages=[\n",
    "            {'role': 'system', 'content': REWRITE_SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': REWRITE_USER_TEMPLATE.format(paragraph)}\n",
    "        ],\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Read human_version paragraphs and rewrite each one\n",
    "with open(extracted_csv, 'r', encoding='utf-8') as infile, open(rewritten_csv, 'w', encoding='utf-8', newline='') as outfile:\n",
    "    reader = csv.DictReader(infile)\n",
    "    fieldnames = list(reader.fieldnames) + ['llm_version']\n",
    "    writer = csv.DictWriter(outfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    for row in reader:\n",
    "        human_version = row['human_version']\n",
    "        llm_version = rewrite_paragraph(human_version)\n",
    "        row['llm_version'] = llm_version\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(f'Rewritten paragraphs saved to {rewritten_csv}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60c0ca",
   "metadata": {},
   "source": [
    "## 5. Load and Verify Dataset\n",
    "\n",
    "Load the human-written paragraphs and their LLM-rewritten versions to verify the dataset before creating the fine-tuning format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = pd.read_csv(rewritten_csv)\n",
    "df_pairs = df_pairs.dropna(subset=['human_version', 'llm_version'])\n",
    "print(f'Dataset contains {len(df_pairs)} paragraph pairs')\n",
    "df_pairs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bb95b9",
   "metadata": {},
   "source": [
    "## 6. Format as OpenAI Fine-Tuning JSONL\n",
    "\n",
    "For each pair, create a JSONL entry with the LLM version as the user prompt and the human version as the assistant response, using the specified system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09ebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = 'You are a report writing editor. Respond with the re-written text only, without any additional commentary or explanation.'\n",
    "user_template = (\n",
    "    'Re-write the following text to make it as good as possible. You should maintain all the meaning, '\n",
    "    'however you should change order, structure, word choice etc. to improve it. Input text: {}'\n",
    ")\n",
    "\n",
    "jsonl_path = Path('training_data.jsonl')\n",
    "with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
    "    for _, row in df_pairs.iterrows():\n",
    "        entry = {\n",
    "            'messages': [\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': user_template.format(row['llm_version'])},\n",
    "                {'role': 'assistant', 'content': row['human_version']}\n",
    "            ]\n",
    "        }\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n",
    "print(f'Saved fine-tuning data to {jsonl_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63788326",
   "metadata": {},
   "source": [
    "## 7. Fine-tuning\n",
    "\n",
    "- Review the generated JSONL file for quality and completeness\n",
    "- Use the file as input for OpenAI fine-tuning via the API or web interface\n",
    "- Optionally, expand the dataset with more paragraphs for improved results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
